import os
import threading
import traceback
import uvicorn
import numpy as np
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from typing import Dict, Any, List, Optional

# LAW #1: Dashboard does NOT import core services that access databases
# from src.core.embeddings import get_embedding_service  # DISABLED
from src.utils.logger import get_logger
from src.utils.config import get_config

logger = get_logger(__name__)

async def compute_semantic_edges(memory_nodes: List[Dict], top_k: int = 5, min_threshold: float = 0.1) -> List[Dict]:
    """
    Compute semantic similarity edges between memory nodes using embeddings.
    
    LAW #1 ENFORCEMENT: This function is DISABLED at runtime to prevent
    database locks. Semantic edges should be pre-computed in the snapshot
    generation script (scripts/update_dashboard_data.py) instead.
    """
    # DISABLED: Runtime embedding computation causes lock contention
    # TODO: Move semantic edge computation to snapshot generation script
    return []

app = FastAPI(title="Elefante Knowledge Garden")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Endpoints
@app.get("/api/graph")
async def get_graph(limit: int = 1000, space: Optional[str] = None):
    """
    Fetch graph data from pre-generated snapshot file (ChromaDB memories + Kuzu entities).
    The snapshot is generated by scripts/update_dashboard_data.py
    """
    import json
    from pathlib import Path
    from src.utils.config import DATA_DIR
    
    try:
        snapshot_path = DATA_DIR / "dashboard_snapshot.json"
        
        if not snapshot_path.exists():
            logger.warning("Snapshot not found, returning empty graph")
            return {
                "nodes": [],
                "edges": [],
                "stats": {"node_count": 0, "edge_count": 0, "semantic_edge_count": 0}
            }
        
        with open(snapshot_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # Transform nodes to frontend format
        nodes = []
        for n in data.get("nodes", []):
            node_type = n.get("type", "memory")
            nodes.append({
                "id": n.get("id"),
                "label": n.get("name", "")[:50] + ("..." if len(n.get("name", "")) > 50 else ""),
                "type": node_type,
                "entityType": node_type,
                "properties": {
                    "description": n.get("description", ""),
                    "created_at": n.get("created_at", ""),
                    **(n.get("properties", {}) if isinstance(n.get("properties"), dict) else {})
                },
                "full_data": n
            })
        
        # Transform edges to frontend format
        edges = []
        node_ids = {n["id"] for n in nodes}
        for e in data.get("edges", []):
            src = e.get("from") or e.get("source")
            dst = e.get("to") or e.get("target")
            if src in node_ids and dst in node_ids:
                label = e.get("label", "RELATED")
                edge_type = e.get("type") or ("semantic" if label == "SIMILAR" else "graph")
                edges.append({
                    "source": src,
                    "target": dst,
                    "type": edge_type,
                    "label": label,
                    "similarity": e.get("similarity"),
                    "properties": {}
                })
        
        # Compute semantic similarity edges for better visualization
        memory_nodes = [n for n in nodes if n["type"] == "memory"]
        semantic_edges = await compute_semantic_edges(memory_nodes, top_k=3, min_threshold=0.3)
        edges.extend(semantic_edges)
        
        logger.info(f"Loaded {len(nodes)} nodes, {len(edges)} edges from snapshot")
        
        return {
            "nodes": nodes,
            "edges": edges,
            "stats": {
                "node_count": len(nodes),
                "edge_count": len(edges),
                "semantic_edge_count": len(semantic_edges)
            }
        }
        
    except Exception as e:
        logger.error(f"Failed to fetch graph data: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/search")
async def search_memories(query: str, limit: int = 5, min_similarity: float = 0.5):
    """
    Search memories using semantic search.
    This endpoint is designed for the VS Code extension grounding feature.
    
    Note: This breaks LAW #1 during search but is acceptable for quick reads.
    The connection is released immediately after the search.
    """
    from src.core.vector_store import get_vector_store
    
    try:
        # Quick read-only operation
        vector_store = get_vector_store()
        results = await vector_store.search(query, limit=limit, min_similarity=min_similarity)
        
        return {
            "success": True,
            "count": len(results),
            "results": [r.to_dict() for r in results]
        }
    except Exception as e:
        logger.error(f"Search failed: {e}")
        return {"success": False, "count": 0, "results": [], "error": str(e)}


@app.get("/health")
async def health_check():
    """Simple health check endpoint for connection testing"""
    return {"status": "ok", "service": "elefante-dashboard"}


@app.get("/api/stats")
async def get_stats():
    """Get system statistics from snapshot (LAW #1: No direct DB access)"""
    import json
    from pathlib import Path
    from src.utils.config import DATA_DIR
    from src.utils.config import get_config
    
    try:
        snapshot_path = DATA_DIR / "dashboard_snapshot.json"
        
        if not snapshot_path.exists():
            return {"error": "Snapshot not found. Run update_dashboard_data.py first."}
        
        with open(snapshot_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        cfg = get_config()
        try:
            from src import __version__ as pkg_version
        except Exception:
            pkg_version = None

        snapshot_stat = data.get("stats", {}) if isinstance(data.get("stats", {}), dict) else {}
        snapshot_generated_at = data.get("generated_at", "unknown")

        return {
            "elefante": {
                "package_version": pkg_version,
                "config_version": getattr(cfg.elefante, "version", None),
                "data_dir": str(DATA_DIR),
            },
            "vector_store": {
                "total_memories": snapshot_stat.get("memories", 0),
            },
            "graph_store": {
                "total_entities": snapshot_stat.get("entities", 0),
                "total_relationships": snapshot_stat.get("edges", 0),
            },
            "snapshot": {
                "path": str(snapshot_path),
                "generated_at": snapshot_generated_at,
                "total_nodes": snapshot_stat.get("total_nodes", 0),
                "memories": snapshot_stat.get("memories", 0),
                "entities": snapshot_stat.get("entities", 0),
                "edges": snapshot_stat.get("edges", 0),
            }
        }
    except Exception as e:
        logger.error(f"Failed to fetch stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Serve Frontend
# We assume the frontend is built to src/dashboard/ui/dist
frontend_path = os.path.join(os.path.dirname(__file__), "ui", "dist")

if os.path.exists(frontend_path):
    app.mount("/", StaticFiles(directory=frontend_path, html=True), name="static")
else:
    @app.get("/")
    def index():
        return {"message": "Elefante Dashboard API is running. Frontend not found (run 'npm run build' in src/dashboard/ui)."}

def start_server(host: str = "0.0.0.0", port: int = 8000):
    """Start the dashboard server"""
    # Configure Uvicorn to log to stderr to avoid corrupting MCP stdout stream
    # MCP uses stdout for JSON-RPC, so application logs must go to stderr
    log_config = uvicorn.config.LOGGING_CONFIG.copy()
    log_config["handlers"]["default"]["stream"] = "ext://sys.stderr"
    log_config["handlers"]["access"]["stream"] = "ext://sys.stderr"
    
    uvicorn.run(app, host=host, port=port, log_config=log_config)

def serve_dashboard_in_thread(host: str = "0.0.0.0", port: int = 8000):
    """Start the dashboard server in a background thread"""
    thread = threading.Thread(target=start_server, args=(host, port), daemon=True)
    thread.start()
    return thread

if __name__ == "__main__":
    start_server()
